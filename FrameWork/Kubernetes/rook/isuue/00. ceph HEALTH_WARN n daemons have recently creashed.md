---
tags:
  - FrameWork
  - Kubernetes
  - Rook
  - Issue
---
### Why??
`kubectl get pods -A`을 검색해보았는데 `osd`의 `RESTARTS`횟수가 카운팅되어 있었습니다. 또한, `Dashboard`에서 `HEALTH_WARN`이라는 문구와 최근에 충돌이 발생했다는 메시지가 메인에 나타나 있어 확인해 보고 해결해 보도록 하죠.

```bash
ceph status

# result
  cluster:
    id:     dad66d63-a75f-44a2-a882-be0ac33bebc7
    health: HEALTH_WARN
            2 daemons have recently crashed

  services:
    mon: 3 daemons, quorum a,b,c (age 24m)
    mgr: a(active, since 23m), standbys: b
    mds: 1/1 daemons up, 1 hot standby
    osd: 9 osds: 9 up (since 5m), 9 in (since 2d)

  data:
    volumes: 1/1 healthy
    pools:   3 pools, 49 pgs
    objects: 27 objects, 696 KiB
    usage:   330 MiB used, 147 GiB / 147 GiB avail
    pgs:     49 active+clean

  io:
    client:   1.2 KiB/s rd, 2 op/s rd, 0 op/s wr
```

이미 지난 에러의 경우에도 확인하고 넘어가지 않으면 지속해서 `health`의 상태가 `OK`로 변하지 않게되니 확인을 해주어야 합니다.

이 녀석의 건강상태를 챙겨주기 위해 해당 문제를 해결해보도록 합시다.

### 해결 방법
우선 `ceph`의 `crash`에 대한 정보는 `crash`모듈이 `daemon creashdumps`정보를 수집하고 `ceph cluster`에 저장하는데요.

다음 명령어를 통해 해당 내용을 조회할 수 있습니다.
`ceph-tools`로 접속해서 확인해 보도록 합시다.

```bash
kubectl exec -it -n ${name-space} ${pod-name} -- bash
ceph crash ls

# result
ID                                                                ENTITY                NEW
2024-06-26T00:31:58.204664Z_3b075ac3-618f-4209-83c6-eb8cdf1d53ea  client.ceph-exporter   *
2024-06-28T01:06:04.036048Z_59541095-464b-450e-a32b-8456577e2979  client.ceph-exporter   *
```

`crash`에 대한 정보를 보고 싶다면 `info`명령을 사용하면 됩니다.

```bash
ceph crash info ${id}
```

이제 아카이브를 추가해주면 해당 문제는 해결됩니다.

```bash
ceph crash archive ${crash-id}

# result
{
    "archived": "2024-06-28 06:31:40.499412",
    "backtrace": [
        "/lib64/libpthread.so.0(+0x12d20) [0x7fde255bad20]",
        "gsignal()",
        "abort()",
        "/lib64/libstdc++.so.6(+0x9009b) [0x7fde2426f09b]",
        "/lib64/libstdc++.so.6(+0x9654c) [0x7fde2427554c]",
        "/lib64/libstdc++.so.6(+0x965a7) [0x7fde242755a7]",
        "/lib64/libstdc++.so.6(+0x96808) [0x7fde24275808]",
        "(boost::json::detail::throw_invalid_argument(char const*, boost::source_location const&)+0xa3) [0x558698a51029]",
        "ceph-exporter(+0x5a0cc) [0x558698a510cc]",
        "ceph-exporter(+0x5c06d) [0x558698a5306d]",
        "ceph-exporter(+0x7f5d0) [0x558698a765d0]",
        "ceph-exporter(+0x7fbdd) [0x558698a76bdd]",
        "(boost::asio::detail::scheduler::do_run_one(boost::asio::detail::conditionally_enabled_mutex::scoped_lock&, boost::asio::detail::scheduler_thread_info&, boost::system::error_code const&)+0x3ea) [0x558698a7d48a]",
        "ceph-exporter(+0x729b1) [0x558698a699b1]",
        "(DaemonMetricCollector::main()+0x9b) [0x558698a5544b]",
        "main()",
        "__libc_start_main()",
        "_start()"
    ],
    "ceph_version": "18.2.2",
    "crash_id": "2024-06-26T00:31:58.204664Z_3b075ac3-618f-4209-83c6-eb8cdf1d53ea",
    "entity_name": "client.ceph-exporter",
    "os_id": "centos",
    "os_name": "CentOS Stream",
    "os_version": "8",
    "os_version_id": "8",
    "process_name": "ceph-exporter",
    "stack_sig": "872df1384e30f76b90459614f7a6d7c309e48cac7a8c18f8f461cf9829b58001",
    "timestamp": "2024-06-26T00:31:58.204664Z",
    "utsname_hostname": "rook-ceph-exporter-kube01-57bb65465c-5mq44",
    "utsname_machine": "x86_64",
    "utsname_release": "5.15.0-112-generic",
    "utsname_sysname": "Linux",
    "utsname_version": "#122-Ubuntu SMP Thu May 23 07:48:21 UTC 2024"
}
```

다시한번 `crash`내역을 조회해 보면 `NEW`가 해결된걸 확인 할 수 있는데요.

```bash
ceph crash ls
# result
ID                                                                ENTITY                NEW
2024-06-26T00:31:58.204664Z_3b075ac3-618f-4209-83c6-eb8cdf1d53ea  client.ceph-exporter   
2024-06-28T01:06:04.036048Z_59541095-464b-450e-a32b-8456577e2979  client.ceph-exporter   *
```

이젠 나머지 한녀석도 아카이브를 추가하고 상태를 확인해 보면 건강해진걸 확인할 수 있어요!!

```bash
ceph status

# result
  cluster:
    id:     dad66d63-a75f-44a2-a882-be0ac33bebc7
    health: HEALTH_OK

  services:
    mon: 3 daemons, quorum a,b,c (age 29m)
    mgr: a(active, since 28m), standbys: b
    mds: 1/1 daemons up, 1 hot standby
    osd: 9 osds: 9 up (since 10m), 9 in (since 2d)

  data:
    volumes: 1/1 healthy
    pools:   3 pools, 49 pgs
    objects: 27 objects, 696 KiB
    usage:   330 MiB used, 147 GiB / 147 GiB avail
    pgs:     49 active+clean

  io:
    client:   852 B/s rd, 1 op/s rd, 0 op/s wr
```

---
# Tip!!
### 한번에 처리하기
만약 하나하나 확인하고 처리하기가 귀찮다면.... 한번에 처리하면 됩니다.

```bash
ceph crash archive-all
```