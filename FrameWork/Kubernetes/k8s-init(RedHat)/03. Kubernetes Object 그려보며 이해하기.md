---
tags:
  - FrameWork
  - Kubernetes
  - RedHat
  - Object
---
# .yaml파일에 각 속성에 대해 이해하기
## 폴더생성
### master Node에 접속해 디렉토리를 생성

```bash
mkdir -p /root/k8s-local-volume/1231
```

![[스크린샷 2025-03-07 오후 5.13.00.png]]

## .yaml의 metadata에 있는 labels 파헤치기
우리는 옷을 사던 어떤 제품을 사면 해당 제품에 `label`을 볼 수 있습니다. 이 `label`들은 이 제품이 어떤 제품인지에 대한 `명세`를 해주는 부분이지요. `metadata`에 있는 `label`s안에 내용들도 마찬가지 입니다. 

다른 Ojbect들끼리의 연결에도 중요한 역할을 하니 잘 알아 두어야 합니다. 아래 이미지를 보시면 `selector`를 이용해서 해당 Object의 `labels`의 정보로 어떤 Object가 어떤 Object에 연결될 것인지를 판단하게 됩니다.

그럼 각각 무엇을 나타내는지 알아 볼까요??

### part-of
- 어플리케이션의 전체적인 이름
### component
- 구성요소
- 해당 어플리케이션이 어떤것으로 만들어져 있는지, 구성되어 있는지를 명세합니다.
- ex) `prometheus`
### name
- 어플리케이션의 이름
- ex) `prometheus`
### instance
- 인스턴스 식별자
- 목적에 따라 여러개를 작성할 수 있다.
- ex) k8s, k8s-1, k8s-2, k8s-rule, ...
### version
- 버전
- App버전 변경시에는 수정이 필요

![[스크린샷 2025-03-07 오후 6.45.22.png]]

## Cluster를 기준으로 labels를 파헤쳐보기
우리는 위에서 `Namespace`를 기준으로 `labels`를 어떻게 사용하는지 어떻게 연결하고 어디에 필요한지를 알아보았습니다.

하지만, 이것은 `Namespace`에 Object에 국한된 것이 아닌 `Cluster`에서도 포함이 되는데요.
실제 예로 `PV`는 `Namespace`에 속하지 않고 `Cluster`영영에 속하게 됩니다.

`PV`에서는 `selector`가 아닌 `nodeAffinity`속성으로 `Master Node`와 연결 시킵니다.
`Pod`1의 경우에는 `nodeSelector`속성으로 `Master Node`와 연결을 시키죠.

또한, `labels`속성 값들 앞에 prefix를 붙여 사용 할 수도 있습니다.
보통 도메인주소를 붙이는데 다양한 툴을 공부할 때에 해당 도메인을 많이 보시게 될겁니다.

![[스크린샷 2025-03-07 오후 6.48.11.png]]

## Namespace
- Cluster level의 Object를 그루핑해주는 역할

### metadata
1. name
	- Namespace의 이름

```yaml title:namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: anotherclass-123
  labels:
    part-of: k8s-anotherclass
    managed-by: dashboard
```

![[스크린샷 2025-03-07 오후 5.13.39.png]]

## Deployment
- Pod를 만들고 Upgrade를 해주는 역할

### metadata
1. namespace
	- 위에서만든 namespace에 소속시키기 위한 metadata
2. name
	- Deployment의 이름이되고 이 이름은 같은 Object타입이라면 고유값으로 작성(중복 X)

### replicas
- Pod을 몇개 만들껀지 결정

### template
- Pod를 어떻게 구성할지에 대한 내용
	
```yaml title:deployment.yaml
apiVersion: apps/v1  
kind: Deployment  
metadata:  
  namespace: anotherclass-123  
  name: api-tester-1231  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
    version: 1.0.0  
    managed-by: dashboard  
spec:  
  selector:  
    matchLabels:  
      part-of: k8s-anotherclass  
      component: backend-server  
      name: api-tester  
      instance: api-tester-1231  
  replicas: 2  
  strategy:  
    type: RollingUpdate  
  template:  
    metadata:  
      labels:  
        part-of: k8s-anotherclass  
        component: backend-server  
        name: api-tester  
        instance: api-tester-1231  
        version: 1.0.0  
    spec:  
      # Pod를 띄울 Node를 선택  
      nodeSelector:  
        kubernetes.io/hostname: k8s-master  
      containers:  
        - name: api-tester-1231  
          # docker hub(이미지 보관소)에 있는 이미지 선택  
          image: 1pro/api-tester:v1.0.0  
          ports:  
          - name: http  
            containerPort: 8080  
          # application의 환경변수와 관련된 부분  
          envFrom:  
            ## 환경변수의 값을 제공해주는 역할  
            - configMapRef:  
                name: api-tester-1231-properties  
          # App이 잘 기동되어 있는지 체크하다가 기동안되면 App 재기동하는 역할  
          # 성공시 밑의 readinessProbe와 livenessProbe를 실행시키  
          startupProbe:  
            httpGet:  
              path: "/startup"  
              port: 8080  
            periodSeconds: 5  
            failureThreshold: 36  
          # App의 트래픽을 연결할건지에 대한 속성  
          readinessProbe:  
            httpGet:  
              path: "/readiness"  
              port: 8080  
            periodSeconds: 10  
            failureThreshold: 3  
          # App이 정상이 아니면 재시작을 시킬것인지 판단하는 속성  
          livenessProbe:  
            httpGet:  
              path: "/liveness"  
              port: 8080  
            periodSeconds: 10  
            failureThreshold: 3  
          # Pod하나 사용할 리소스자원을 정해주는 역할  
          resources:  
            requests:  
              memory: "100Mi"  
              cpu: "100m"  
            limits:  
              memory: "200Mi"  
              cpu: "200m"  
          # Pod내부에 만들어지는 디렉토리  
          volumeMounts:  
            - name: files # volumes의 name과 연결되는 이름  
              mountPath: /usr/src/myapp/files/dev  
            - name: secret-datasource # volumes의 name과 연결되는 이름  
              mountPath: /usr/src/myapp/datasource  
      volumes:  
        - name: files # volumeMounts의 name과 연결되는 이름  
          persistentVolumeClaim:  
            claimName: api-tester-1231-files  
        - name: secret-datasource # volumeMounts의 name과 연결되는 이름  
          secret:  
            secretName: api-tester-1231-postgresql
```

![[스크린샷 2025-03-07 오후 5.14.23.png]]

## Service
- Pod한테 트래픽을 연결시켜주는 역할

```yaml title:service.yaml
apiVersion: v1  
kind: Service  
metadata:  
  namespace: anotherclass-123  
  name: api-tester-1231  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
    version: 1.0.0  
    managed-by: dashboard  
spec:  
  selector:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
  ports:  
    - port: 80  
      targetPort: http  
      nodePort: 31231  
  type: NodePort
```

![[스크린샷 2025-03-07 오후 5.19.54.png]]

## Configmap, Secret
- Configmap : Pod에 환경변수를 제공하는 역할

```yaml title:configmap.yaml
apiVersion: v1  
kind: ConfigMap  
metadata:  
  namespace: anotherclass-123  
  name: api-tester-1231-properties  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
    version: 1.0.0  
    managed-by: dashboard  
data:  
  spring_profiles_active: "dev"  
  application_role: "ALL"  
  postgresql_filepath: "/usr/src/myapp/datasource/postgresql-info.yaml"
```

- Secret : Pod에 좀 더 중요한 값을 제공하는 역할

```yaml title:secret.yaml
apiVersion: v1  
kind: ConfigMap  
metadata:  
  namespace: anotherclass-123  
  name: api-tester-1231-properties  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
    version: 1.0.0  
    managed-by: dashboard  
data:  
  spring_profiles_active: "dev"  
  application_role: "ALL"  
  postgresql_filepath: "/usr/src/myapp/datasource/postgresql-info.yaml"
```

![[스크린샷 2025-03-07 오후 5.25.14.png]]

## PVC(Persistent Volume Claim), PV(Persistent Volume)
### PVC
- 사용자가 요청하는 스토리지의 요구 사항
- 예를 들어보겠습니다. 우리는 10Gb가 할당된 PV를 5개의 Pod에서 나눠서 사용 할 수 있습니다. 이럴 경우 PVC를 각각 Pod에 작성하여 storage를 2Gb씩 나눠서 사용 할 수 있도록 명세하는 것이죠.

```yaml title:PVC.yaml
apiVersion: v1  
kind: PersistentVolumeClaim  
metadata:  
  namespace: anotherclass-123  
  name: api-tester-1231-files  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
    version: 1.0.0  
    managed-by: kubectl  
spec:  
  resources:  
    requests:
      # volume의 용량을 정의  
      storage: 2G  
  # 접근 권한 설정(읽기, 쓰기, 읽기 & 쓰기)
  accessModes:  
    - ReadWriteMany  
  selector:  
    matchLabels:  
      part-of: k8s-anotherclass  
      component: backend-server  
      name: api-tester  
      instance: api-tester-1231-files
```

### PV
- Cluster level의 Object로 실제 Volume을 지정하는 역할

```yaml title:PV.yaml
apiVersion: v1  
kind: PersistentVolume  
metadata:  
  name: api-tester-1231-files  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231-files  
    version: 1.0.0  
    managed-by: dashboard  
spec:  
  capacity:  
    storage: 2G  
  volumeMode: Filesystem  
  accessModes:  
    - ReadWriteMany  
  # 이 path를 Volume으로 사용하겠다는 의미
  local:  
    # 미리 폴더를 만들어 두어야함
    path: "/root/k8s-local-volume/1231"  
  # 대상 Node를 선택하는 것
  nodeAffinity:  
    required:  
      nodeSelectorTerms:  
        - matchExpressions:  
            - {key: kubernetes.io/hostname, operator: In, values: [k8s-master]}
```

![[스크린샷 2025-03-07 오후 5.34.54.png]]

## HPA
- 부하에 따라 Pod를 늘려주고 줄여주는 스케일링 역할

```yaml
apiVersion: autoscaling/v2  
kind: HorizontalPodAutoscaler  
metadata:  
  namespace: anotherclass-123  
  name: api-tester-1231-default  
  labels:  
    part-of: k8s-anotherclass  
    component: backend-server  
    name: api-tester  
    instance: api-tester-1231  
    version: 1.0.0  
    managed-by: dashboard  
spec:
  # 스케일링 대상 설정
  scaleTargetRef:  
    apiVersion: apps/v1  
    kind: Deployment  
    name: api-tester-1231  
  # 최소 몇개의 Pod를 가지고 있을 것인지
  minReplicas: 2  
  # 최대 몇개의 Pod를 가지고 있을 것인지
  maxReplicas: 4
  # 스케일 out 조건 설정
  metrics:  
    - type: Resource  
      resource:  
        name: cpu  
        target:  
          type: Utilization  
          averageUtilization: 60
  # 동작 상세 설정
  behavior:  
    scaleUp:  
      stabilizationWindowSeconds: 120
```

![[스크린샷 2025-03-07 오후 5.39.32.png]]


> 이 글은 인프런의 일프로님 강의를 기반으로 작성되었습니다.