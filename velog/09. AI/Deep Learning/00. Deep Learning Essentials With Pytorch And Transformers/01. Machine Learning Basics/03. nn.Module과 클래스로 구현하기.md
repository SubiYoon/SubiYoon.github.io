---
tags:
  - AI
  - DeepLearning
  - MachineLearning
  - eBook
---
# nn.Module과 클래스로 구현하기
파이토치에서는 선형 회귀 모델이 `nn.Linear()`라는 함수로, 평균 제곱 오차가 `nn.functional.mse_loss()`라는 함수로 구현되어져 있습니다.

```python
import torch.nn as nn

model = nn.Linear(input_dim, output_dim)
```

```python
import torch.nn.functional as F

cost = F.mse_loss(predication, y_train)
```

## 01. 단순 선형 회귀 구현하기
우선 기본적으로 다음과 같이 작성합니다.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)
```

아래 데이터는 $y=2x$를 가정된 상태에서 만들어진 데이터입니다.
우리는 $W=2, b=0$ 임을 이미 이전에 밝혀냈습니다.
모델이 이 두 $W$와 $b$의 값을 제대로 찾아내도록 하는 것이 목표입니다.

```python
# Data
x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[2], [4], [6]])
```

데이터는 정의햇으니, 이제 모델을 구현해 보겠습니다.
`nn.Linear()`는 입력의 차원, 출력의 차원을 인수로 받습니다.

```python
model = nn.Linear(1, 1)
```

하나의 입력 $x$에 대해 하나의 출력 $y$를 가지므로 입력과 출력의 차원은 모두 1입니다.
변수 `model`에는 가중치 $W$와 편향 $b$가 저장되어져 있습니다.
이 값들은 `model.parameters()`라는 함수로 불러 올 수 있습니다.

```python
print(model.parameters())
```

```bash
[Parameter containing:tensor([[0.5153]], requires_grad=True), Parameter containing:tensor([-0.4414], requires_grad=True)]
```

첫번째 값이 가중치인 $W$이고 두번째 값이 편향인 $b$에 해당합니다.

옵티마이저를 정의해볼까요?

```python
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
```

2000회를 반복해 봅시다.

```python
nb_epochs = 2000
for epoch in range(nb_epochs + 1):
    # H(X) 계산
    prediction = model(x_train)
    
    # cost 계산(torch에서 제공하는 평균 제곱 오차 함수)
    cost = F.mse_loss(prediction, y_train)
    
    # cost로 H(X) 개선하는 부분
    # gradient를 0으로 초기화
    optimizer.zero_grad()
    
    # 비용 함수르 미분하여 gradient 계산
    cost.backward()
    
    # W와 b를 업데이트
    optimizer.step()
    
    if epoch % 100 == 0:
        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost, cost.item()))
```

```bash
Epoch 0/2000 Cost: 13.103540
... 중 략...
Epoch 2000/2000 Cost: 0.000000
```

학습이 완료되었습니다.
$W$와 $b$의 값이 최적화가 되었는지 확인을 해보기위해 $x$에 임의의 값 4를 넣어 $y$를 예측해보죠.

```python
# 임의의 값 4 입력
new_var = torch.FloatTensor([4.0])
# 입력한 값 4에 대해서 예측값 y를 리턴받아 pred_y에 저장
pred_y = model(new_var) # forward 연산
# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나오면 됨
print("4의 예측값 : ", pred_y)
```

```bash
훈 련 후 입 력 이 4 일 때 의 예 측 값 : tensor([[7.9989]], grad_fn=<AddmmBackward>)
```

정답이 8이므로 실제 측정된 값인 7.9989면 8에 가깝기 때문에 잘 예측되었다고 볼 수 있습니다.

학습 후의 $W$와 $b$의 값을 출력해 봅시다.

```python
print(list(model.parameters()))
```

```bash
[Parameter containing:
tensor([[1.9994]], requires_grad=True), Parameter containing:
tensor([0.0014], requires_grad=True)]
```

$W$는 2에 가깝고 $b$는 0에 가까운 것을 볼 수 있습니다.
- $H(x)$식에 입력 $x$로 부터 예측된 $y$를 얻는 것을 forward 연산이라고 합니다.
- 학습 전, prediction = model(x_train)은 x_train으로부터 예측값을 리턴하므로 forward연산입니다.
- 학습 후, pred_y = model(new_var)는 임의의 값 new_var로부터 예측값을 리턴하므로 forward연산입니다.
- 학습과정에서 비용 함수를 미분하여 기울기를 구하는 것을 backward연산이라고 합니다.
- cost.backwar()는 비용함수로부터 기울기를 구하라는 의미이며 backward연산입니다.


## 02. 다중 선형 회귀 구현하기
위에서 했던 과정과 큰 차이는 없습니다. 바로 구현해 봅시다.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)
```

여기서는 3개의 $x$로부터 하나의 $y$를 예측하는 문제였죠??
즉, 가설 수식은 $H(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b$입니다.

```python
# 데 이 터
x_train = torch.FloatTensor([[73, 80, 75],
                            [93, 88, 93],
                            [89, 91, 90],
                            [96, 98, 100],
                            [73, 66, 70]])
y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])
```

```python
model = nn.Linear(3, 1)
```

3개의 input에 대해 1개의 output이 발생하므로 `nn.Linear()`호출시 인자를 아래와 같이 넣어줍니다. 이렇게 model에는 3개의 가중치와 1개의 편향이 저장되어져 있습니다.

이제 그 값을 출력해봅시다.

```python
print(list(model.parameters()))
```

첫번째 출력되는 것이 3개의 $W$이고 두번째 출력되는 것이 $b$입니다.
지금은 각 값이 예측되지 않은 상태로 랜덤 초기화되어 있는 상태입니다.

```bash
[Parameter containing:
tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:
tensor([0.2710], requires_grad=True)]
```

이제 옵티마이저를 정의합니다. model.parameters()를 사용하여 3개의 $W$와 1개의 $b$를 전달합니다.
이번에 학습률은 0.00001로 정의합니다. 파이썬 코드로는 `1e-5`라고 표기하기도 합니다.
(여기서 0.01로 하지 않는 이유는 기울기가 발산하기 때문입니다.)

![[스크린샷 2026-01-19 오전 10.52.08.png]]

```python
optimizer = optim.SGD(model.parameters(), lr=1e-5)
```

이하 코드는 단순 선형 회귀를 구현했을 때와 동일 합니다.

```python
nb_epochs = 2000
for epoch in range(nb_epochs + 1):
    # H(X) 계산
    prediction = model(x_train)
    
    # cost 계산(torch에서 제공하는 평균 제곱 오차 함수)
    cost = F.mse_loss(prediction, y_train)
    
    # cost로 H(X) 개선하는 부분
    # gradient를 0으로 초기화
    optimizer.zero_grad()
    
    # 비용 함수르 미분하여 gradient 계산
    cost.backward()
    
    # W와 b를 업데이트
    optimizer.step()
    
    if epoch % 100 == 0:
        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost, cost.item()))
```

```bash
Epoch 0/2000 Cost: 31667.597656
Epoch 2000/2000 Cost: 0.199777
```

학습이 완료 되었습니다.
어디 $W$와 $b$가 잘 예측되었는지 확인해 볼까요??

```python
# 임 의 의 입 력 [73, 80, 75] 를 선 언
new_var = torch.FloatTensor([[73, 80, 75]])
# 입 력 한 값 [73, 80, 75] 에 대 해 서 예 측 값 y 를 리 턴 받 아 서 pred_y 에 저 장
pred_y = model(new_var)
print(" 훈 련 후 입 력 이 73, 80, 75 일 때 의 예 측 값 :"
, pred_y)
```

```bash
훈 련 후 입 력 이 73, 80, 75 일 때 의 예 측 값 : tensor([[151.2305]], grad_fn=<AddmmBackward>)
```

```python
print(list(model.parameters()))
```

```bash
[Parameter containing:
tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:
tensor([0.2802], requires_grad=True)]
```

잘 예측된 것을 확인 할 수 있습니다.


## 03. 모델을 클래스로 구현하기
파이토치의 대부분의 구현체들은 대부분 모델을 생성할 때 클래스(Class)를 사용하고 있습니다.
앞서 배운 선형 회귀를 클래스로 구현해보겠습니다.

앞서 단순 선형 회귀 모델은 다음과 같이 구현했었습니다.

```python
import torch
import torch.nn as nn

class LinearRegressionModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(1, 1) # 단순 선형 회귀이므로 input_dim = 1, output_dim = 1
     
    def forward(self, x):
        return self.linear(x)
```

```python
model = LinearRegressionModel()
```

Class형태의 모델은 `nn.Module`을 상속받습니다. 그리고 \_\_init\_\_()에서 모델의 구조와 동작을 정의하는 생성자를 정의합니다.
`forward`함수는 연산을 진행시키는 함수입니다.
예를 들어 model이란 이름의 객체를 생성 후, model(입력 데이터)와 같은 형식으로 객체를 호출하면 자동으로 forward연산이 수행됩니다.
- $H(x)$식에 $x$로부터 예측된 $y$를 얻는 것을 forward연산이라고 합니다.


다중 선회 회귀모델은 다음과 같이 구현했었습니다.

```python
model = Linear(3, 1)
```

이를 Class로 구현하면 다음과 같습니다.

```python
import torch
import torch.nn

class MultivariateLinearRegressionModel(nn.Module):
    def __init__(self):
        super.__init__()
        self.linear = nn.Linear(3, 1)
    
    def forward(self, x):
        return self.linear(x)
```

```python
model = MultivariateLinearRegressionModel()
```