---
tags:
  - AI
  - FineTuning
  - UFT
  - SFT
cf: "[[velog/09. AI/README|README]]"
---
## 파인튜닝의 유형
파인튜닝에 사용되는 데이터셋 유형에 따라 `지도 파인튜닝(Supervised Fine Tuning)`과 `비지도 파인튜닝(Unsupervised Fine Tuning)`의 두가지 유형이 있습니다.

### 비지도 파인 튜닝 (UFT)
라벨이 없는 데이터셋을 활용해 모델을 학습시키는 방법입니다.
데이터에 내재된 패턴과 구조를 스스로 학습하게 됩니다. 주로 데이터의 고유한 구조를 활용하거나 새로운 데이터를 생성하면서 `모델의 표현력을 향상시키는 데 목적`이 있습니다.
이 모델의 경우에는 더 유용한 특징을 스스로 찾아내도록 돕습니다.

### 지도 파인튜닝 (SFT)
라벨이 포함된 고품질 데이터셋을 사용해 사전 학습된 모델을 특정 목적에 맞게 조정하는 방법입니다.
라벨이 주어짐으로써 모델은 원하는 결과를 명확하게 학습할 수 있고, 이를 통해 성능 최적화가 가능합니다.
보통 분류작업처럼 각 샘플에 정답이 포함된 데이터셋이 사용됩니다. 이러한 맞춤형 파인튜닝은 범용 모델을 특정 분야에 최적화하여 정확도, 효율성, 그리고 비지니스 가치를 높이는 데 기여합니다.

#### SFT 데이터셋이란?
특정 작업이나 분야에 맞춰 구조화된 형태로 구성된 학습용 데이터를 의믜합니다.
이 데이터 셋은 `Input 값`에 대응하는 `Output`값을 포함하고 있어, 학습 과정에서 모델이 올바른 출력을 생성할 수 있도록 도와줍니다.

#### 프리 트레이닝(Pre Training)과 파인튜닝 비교
1. 프리 트레이닝(Pre Training)
    - 용도 : 자연어 처리와 같은 일반화 가능한 기술에 대한 모델 학습
    - 데이터 요구사항 : 대규모 멀티 도메인 데이터 세트, 정확도 필터링
    - 결과 : 다양한 적용 사례에서 작동하는 파운데이션 모델 구축

2. 파인튜닝(Fine Tuning)
    - 용도 : 특정 사용 사례 및 목표에 맞춘 LLM 구조
    - 데이터 요구사항 : 소규모 전문 데이터 세트, 특정 사용 사례에 맞춘 큐레이션
    - 결과 : 특정 작업 및 도메인에 맞게 모델 성능 조정

#### SFT 작동 원리
1. 데이터 수집 및 준비
2. 데이터 어노테이션 및 품질 관리
3. 모델 가중치 조정
    - 수집한 구조화된 데이터를 이용해 사전 학습된 모델의 가중치를 조정합니다.
    - 주로 낮은 학습룰을 사용하여 새로운 작업에 특화되도록 학습시키면서 기존의 일반화된 지식도 유지하게 되는데, 주로 경사하강법, 역전파 등의 방법이 활용됩니다.
4. 모델 평가와 반복 개선

#### SFT 기법
##### Full Fine Tuning
작업별 데이터 세트를 사용하여 `모든` 모델 매개변수를 파인튜닝합니다.
- 장점 : 컨트롤 능력과 성능을 극대화합니다.
- 단점 : 대용량 데이터 및 컴퓨팅 요구 사항으로 인해 시간이 많이 소요됩니다.

##### Parameter\-fficient Fine Tuning (PEFT)
매개변수의 일부 하위 집합(ex. 어댑터, LoRA 레이어)을 업데이트 합니다.
- 장점 : 가볍고 빠르며 비용 효율적이며 여러 환경에 배포하기 쉽습니다.
- 단점 : 복잡하거나 위험성이 높은 작업에서는 성능이 저하될 수 있습니다.

##### Instruction Tuning
다양한 작업에서 사람이 직접 작성한 지침을 따르도록 모델을 훈련합니다.
- 장점 : 일반화 및 신속한 팔로업 행동을 향상합니다.
- 단점 : 고도로 기술적인 영역에서는 효과가 떨어집니다.

##### RLHF (Reinforcement Learning from Human Feedback)
강화 학습을 통해 파인튜닝과 인간 피드백을 결합합니다.
- 장점 : 모델 동작을 인간의 가치관에 맞춰 조정하고 출력 품질을 향상합니다.
- 단점 : 설정이 복잡할 수 있으며, 숙련된 어노테이션 작성자와 컴퓨팅이 필요합니다.