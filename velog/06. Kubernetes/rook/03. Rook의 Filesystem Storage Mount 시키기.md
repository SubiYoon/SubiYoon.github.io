---
tags:
  - FrameWork
  - Kubernetes
  - Rook
---
### 개발환경
* ubuntu 22.04
* cri-o
* calico
* kubernetes v1.28

### 환경 설정하기
우선 파일시스템을 생성하기 위해서는 `metadata pool`, `data pools`, `metadata server`에 대한 정보를 세팅해야 합니다.

더 많은 옵션을 확인하기 위해서는 [creating shared filesystems](https://rook.io/docs/rook/latest-release/CRDs/Shared-Filesystem/ceph-filesystem-crd/)을 참고하세요.

그럼 한번 설정파일을 작성해 볼까요??

```yaml title:"filesystem.yaml"
apiVersion: ceph.rook.io/v1
kind: CephFilesystem
metadata:
  name: myfs
  namespace: rook-ceph
spec:
  metadataPool:
    replicated:
      size: 3
  dataPools:
    - name: replicated
      replicated:
        size: 3
  preserveFilesystemOnDelete: true
  metadataServer:
    activeCount: 1
    activeStandby: true
```

적용시켜 봅시다.

```bash
kubectl create -f filesystem.yaml
```

다음 명렁어들을 통해 동작하는지 확인할 수 있습니다.

```bash
kubectl -n rook-ceph get pod -l app=rook-ceph-mds
# result
NAME                                    READY   STATUS    RESTARTS        AGE
rook-ceph-mds-myfs-a-767b59f489-rzssr   2/2     Running   7               2d19h
rook-ceph-mds-myfs-b-5d65c7b4c5-mzc9g   2/2     Running   7 (3h33m ago)   2d19h

ceph status
# result
[...]
  services:
    mds: myfs-1/1/1 up {[myfs:0]=mzw58b=up:active}, 1 up:standby-replay
```

### Provision Storage
Rook이 프로비저닝 스토리지를 시작하려면, `StorageClass`를 생성해야합니다.
`StorageClass`는 `Persistent Volumes`를 사용하기 위해서는 필요하죠.

그럼 한번 `StorageClass`를 생성해봅시다.

```yaml title:"storageClass.yaml"
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-cephfs
  namespace: rook-ceph
  # Change "rook-ceph" provisioner prefix to match the operator namespace if needed
provisioner: rook-ceph.cephfs.csi.ceph.com
parameters:
  # clusterID is the namespace where the rook cluster is running
  # If you change this namespace, also change the namespace below where the secret namespaces are defined
  clusterID: rook-ceph

  # CephFS filesystem name into which the volume shall be created
  fsName: myfs

  # Ceph pool into which the volume shall be created
  # Required for provisionVolume: "true"
  pool: myfs-replicated

  # The secrets contain Ceph admin credentials. These are generated automatically by the operator
  # in the same namespace as the cluster.
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph

reclaimPolicy: Delete
```

### Quotas
`CephFs CSI driver`는 `PVC`의 사이즈를 `Quotas`를 사용하여 설정합니다.

### Consume the Shared Filesystem
**차후 업데이트**