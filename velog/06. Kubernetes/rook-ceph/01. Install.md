---
tags:
  - Kubernetes
  - Rook-Ceph
  - Install
---
## 설치
### 기존 디스크 공장 초기화
#### 1. 각 Resources를 설치한 방법으로 제거
- helm
- \*.yaml

#### 2. 노드 내부에서 Rook/Ceph 데이터 완전 삭제 및 포멧
```
sudo systemctl stop rook-ceph-osd@*
sudo umount /var/lib/rook
sudo rm -rf /var/lib/rook
sudo rm -rf /etc/ceph
sudo rm -rf /var/log/ceph
sudo rm -rf /dev/ceph*

# Ceph 관련 LVM 삭제
sudo pvs | grep ceph
sudo vgs | grep ceph
sudo lvs | grep ceph

# 위에서 나온 ceph 관련 항목 삭제
sudo lvremove -y ceph-*
sudo vgremove -y ceph-*
sudo pvremove -y /dev/sda
sudo pvremove -y /dev/sdb

# 파티션 테이블 삭제
sudo sgdisk --zap-all /dev/sda
sudo sgdisk --zap-all /dev/sdb

# 파일시스템 시그니처 완전 삭제
sudo wipefs --all --force /dev/sda
sudo wipefs --all --force /dev/sdb

# Ceph 관련 파티션 제거
sudo ceph-volume lvm zap /dev/sda --destroy
sudo ceph-volume lvm zap /dev/sdb --destroy

# Ceph의 블루스토어 메타데이터까지 완전히 초기화
sudo dd if=/dev/zero of=/dev/sda bs=1M count=100 oflag=direct,dsync
sudo dd if=/dev/zero of=/dev/sdb bs=1M count=100 oflag=direct,dsync
sudo blkdiscard /dev/sda  # SSD인 경우 빠르게 전체 초기화 가능
sudo blkdiscard /dev/sdb  # SSD인 경우 빠르게 전체 초기화 가능
```

이 명령은 해당 디스크의 모든 데이터를 완전히 삭제한다.
`Ceph가 사용하던 데이터 디스크라면 꼭 확인 후 진행`

#### 3. 기존 OSD 정보가 남아 있을경우 삭제
##### OSD 정보 제거 방법
- PC가 부팅이 안되기 시작하면서 OS를 재설치 한 후에 기존 node정보가 ceph에 남아 있어 OSD 감지하는 Pod가 생성 안되는 이슈가 발생

##### OSD 정보 추출
1. CEPH Tool에 접속
  - 여기서 필요없는 kube33의 정보를 찾는다.
```bash
ceph osd tree
```

##### 단계별 제거 절차
1. OSD를 클러스터에서 "비활성화(out)" 처리

(이미 down 상태이긴 하지만 명시적으로 out 시킴.)

```bash
ceph osd out osd.1
```

2. CRUSH 맵에서 OSD 제거
```bash
ceph osd crush remove osd.1
```

3. 인증 정보(auth) 삭제
```bash
ceph auth del osd.1
```

4. 최종적으로 OSD 삭제
```
ceph osd rm osd.1
```

5. 호스트 노드 제거

  - kube33 자체를 완전히 제거

```bash
ceph osd crush rm kube33
```

단, 다른 OSD가 같은 노드에 없을 경우에만 제거

6. 삭제 확인
```bash
ceph osd tree
```

---
### Helm을 이용한 Rook-Ceph 설치
```bash
# repo 설치
helm repo add rook https://charts.rook.io/release

# rook-ceph 설치
# values-rook-ceph.yaml은 values를 설정한 설정 파일
# version은 선택
helm install rook-ceph rook/rook-ceph --version 1.18.6 -f values-rook-ceph.yaml -n rook-ceph --create-namespace

# rook-ceph-cluster 설치
# values-rook-ceph-cluster.yaml은 values를 설정한 설정 파일
# version은 선택
helm install -n rook-ceph -f values-rook-ceph-cluster.yaml rook-ceph-cluster rook/rook-ceph-cluster --version 1.18.6
```

#### values.yaml 파일 셋팅
1. values-rook-ceph.yaml
```yaml title:"values-rook-ceph.yaml"
cephBlockPoolsVolumeSnapshotClass:
  enabled: true

cephFileSystemVolumeSnapshotClass:
  enabled: true

csi:
  nfs:
    enabled: true
  enableOMAPGenerator: true

monitoring:
  enabled: true
```


2. values-rook-ceph-cluster.yaml
```yaml title:"values-rook-ceph-cluster.yaml"
configOverride: |-
  [mgr]
  cephadm_warn_on_stray_daemons = false
  cephadm_warn_on_stray_hosts = false
|

dashboard:
  enabled: true
  ssl: false

monitoring:
  createPrometheusRules: false
  enabled: true
  metricsDisabled: true

tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule

toolbox:
  enalbed: true
```