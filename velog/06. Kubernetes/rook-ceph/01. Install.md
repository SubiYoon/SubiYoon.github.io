---
tags:
  - Kubernetes
  - Rook-Ceph
  - Install
---
## 설치
### 기존 디스크 공장 초기화
#### 1. 각 Resources를 설치한 방법으로 제거
- helm
- \*.yaml

#### 2. 노드 내부에서 Rook/Ceph 데이터 완전 삭제 및 포멧
```
sudo systemctl stop rook-ceph-osd@*
sudo umount /var/lib/rook
sudo rm -rf /var/lib/rook
sudo rm -rf /etc/ceph
sudo rm -rf /var/log/ceph
sudo rm -rf /dev/ceph*

# Ceph 관련 LVM 삭제
sudo pvs | grep ceph
sudo vgs | grep ceph
sudo lvs | grep ceph

# 위에서 나온 ceph 관련 항목 삭제
sudo lvremove -y ceph-*
sudo vgremove -y ceph-*
sudo pvremove -y /dev/sda
sudo pvremove -y /dev/sdb

# 파티션 테이블 삭제
sudo sgdisk --zap-all /dev/sda
sudo sgdisk --zap-all /dev/sdb

# 파일시스템 시그니처 완전 삭제
sudo wipefs --all --force /dev/sda
sudo wipefs --all --force /dev/sdb

# Ceph 관련 파티션 제거
sudo ceph-volume lvm zap /dev/sda --destroy
sudo ceph-volume lvm zap /dev/sdb --destroy

# Ceph의 블루스토어 메타데이터까지 완전히 초기화
sudo dd if=/dev/zero of=/dev/sda bs=1M count=100 oflag=direct,dsync
sudo dd if=/dev/zero of=/dev/sdb bs=1M count=100 oflag=direct,dsync
sudo blkdiscard /dev/sda  # SSD인 경우 빠르게 전체 초기화 가능
sudo blkdiscard /dev/sdb  # SSD인 경우 빠르게 전체 초기화 가능
```

이 명령은 해당 디스크의 모든 데이터를 완전히 삭제한다.
**Ceph가 사용하던 데이터 디스크라면 꼭 확인 후 진행**

#### 3. 기존 OSD 정보가 남아 있을경우 삭제
##### OSD 정보 제거 방법
PC가 부팅이 안되기 시작하면서 OS를 재설치 한 후에 기존 node정보가 ceph에 남아 있어 OSD 감지하는 Pod가 생성 안되는 이슈가 발생

##### OSD 정보 추출
1. CEPH Tool에 접속
  - 여기서 필요없는 kube33의 정보를 찾는다.
```bash
ceph osd tree
```

##### 단계별 제거 절차
1. OSD를 클러스터에서 "비활성화(out)" 처리

(이미 down 상태이긴 하지만 명시적으로 out 시킴.)

```bash
ceph osd out osd.1
```

2. CRUSH 맵에서 OSD 제거
```bash
ceph osd crush remove osd.1
```

3. 인증 정보(auth) 삭제
```bash
ceph auth del osd.1
```

4. 최종적으로 OSD 삭제
```
ceph osd rm osd.1
```

5. 호스트 노드 제거

  - kube33 자체를 완전히 제거

```bash
ceph osd crush rm kube33
```

단, 다른 OSD가 같은 노드에 없을 경우에만 제거

6. 삭제 확인
```bash
ceph osd tree
```

### helm
helm은 쿠버네티스 리소스를 관리해주는 Manager로 설치 및 수정이 용이합니다. 또한, 버전관리를 할 수 있어. 과거 이력을 알 수 있으며, 다양한 repo들이 Kubernetes 관련 리소스를 설치하는데 용이합니다.

#### 설치
- 설치 방법은 매우 간단하니 홈페이지 링크를 달겠스니다.
- https://helm.sh/docs/intro/install/

### Rook-Ceph
#### values.yaml 파일 셋팅
1. values-rook-ceph.yaml
```yaml title:"values-rook-ceph.yaml"
monitoring:
  enabled: true
```


2. values-rook-ceph-cluster.yaml
```yaml title:"values-rook-ceph-cluster.yaml"
toolbox:
  enalbed: true
```

#### rook-ceph 설치
```bash
# repo 설치
helm repo add rook https://charts.rook.io/release

# rook-ceph 설치
# values-rook-ceph.yaml은 values를 설정한 설정 파일
# version은 선택
helm install rook-ceph rook/rook-ceph --version 1.18.6 -f values-rook-ceph.yaml -n rook-ceph --create-namespace

# rook-ceph-cluster 설치
# values-rook-ceph-cluster.yaml은 values를 설정한 설정 파일
# version은 선택
helm install -n rook-ceph -f values-rook-ceph-cluster.yaml rook-ceph-cluster rook/rook-ceph-cluster --version 1.18.6
```

---
##  TroubleShooting
### Ceph의 상태가 Health_Ok가 아닐 경우
Ceph는 기본적으로 최소 3개의 OSD를 요구합니다. OSD가 3개이상이 올라와있는지 점검해야합니다. OSD란 현재 우리가 사용하고 있는 운영체제가 설치되어 있는 디스크를 제외하고 공장초기화가 된 상태의 디스크를 장착해야합니다.
만약 제대로 인식되어 있지 않는다면 디스크의 mount정보를 확인해서 위에서 실시한 초기화를 해야합니다.

```bash
sudo fdisk -l
```

아래와 같이 나와있다면 OS가 설치되어 있는 `nvme`를 빼고 `/dev/sda` 디스크를 초기화하면 됩니다.
```bash
Disk /dev/loop0: 55.49 MiB, 58183680 bytes, 113640 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/loop1: 55.49 MiB, 58183680 bytes, 113640 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/loop2: 25.16 MiB, 26378240 bytes, 51520 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/loop3: 50.93 MiB, 53399552 bytes, 104296 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/loop4: 50.77 MiB, 53235712 bytes, 103976 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/nvme0n1: 465.76 GiB, 500107862016 bytes, 976773168 sectors
Disk model: SHPP41-500GM
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: gpt
Disk identifier: 62E0DD66-CA73-4C9F-AF20-1760B6F0CE13

Device           Start       End   Sectors   Size Type
/dev/nvme0n1p1    2048   2203647   2201600     1G EFI System
/dev/nvme0n1p2 2203648   6397951   4194304     2G Linux filesystem
/dev/nvme0n1p3 6397952 976771071 970373120 462.7G Linux filesystem


Disk /dev/mapper/ubuntu--vg-ubuntu--lv: 462.71 GiB, 496827891712 bytes, 970366976 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/sda: 238.47 GiB, 256060514304 bytes, 500118192 sectors
Disk model: GIGABYTE GP-GSTF
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
```
